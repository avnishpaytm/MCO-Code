{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"raw_data_26-April'25.csv\"\n",
    "raw_data=pd.read_csv(file,low_memory=False,memory_map=True)\n",
    "data=pd.read_csv(\"format.csv\",memory_map=True)\n",
    "table_data=pd.read_csv(\"table_data.csv\",memory_map=True)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data.insert(5,'q',0)\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_map = table_data.set_index('NODE ID')['Lead Status'].to_dict()\n",
    "raw_data['q'] = raw_data['workflow_node_id'].map(table_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.loc[raw_data['sub_stage1']=='QC_AUTO_APPROVED','q']='Leads QC Auto Approved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['q'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=raw_data.dropna(subset=['q'])\n",
    "\n",
    "raw_data['q'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['remove_date']=raw_data['updated_at'].copy()\n",
    "\n",
    "raw_data['remove_date'] = pd.to_datetime(raw_data['remove_date'])\n",
    "\n",
    "raw_data['remove_date'] = raw_data['remove_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "raw_data['remove_date'] = pd.to_datetime(raw_data['remove_date'])\n",
    "len(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pd.Timestamp.now().normalize()-timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_timestamp = pd.Timestamp.now().normalize()\n",
    "\n",
    "raw_data=raw_data[raw_data['remove_date']!=current_timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=raw_data.drop(columns=['remove_date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['solution_type_level_3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['solution_type_level_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=raw_data[raw_data['solution_type_level_3']!='YBL_LIMIT_ENHANCEMENT']\n",
    "\n",
    "raw_data['solution_type_level_3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['solution_type_level_3']=raw_data['solution_type_level_3'].replace(['ACCOUNT_UPGRADE_LENDING','PROFILE_UPDATE'],'ACCOUNT_UPGRADE')\n",
    "\n",
    "raw_data['solution_type_level_3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.loc[raw_data['agent_team']=='3P FSE','solution_type_level_3']='3P FSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['solution_type_level_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(raw_data))\n",
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Merchant Cust ID', 'Lead_ID', 'Entity_Type', 'Node id', 'Lead_Stage',\n",
    "       'Lead Status', 'Created Timestamp', 'Updated Timestamp',\n",
    "       'Product_Context', 'Name_Match_Status',\n",
    "       'Final TimeStamp', 'QC Panel Successful TimeStamp',\n",
    "       'Last QC Pending Timestamp',\n",
    "       'Stage movement count', 'cust_id', 'agent_team',\n",
    "       'mid', 'mid_created_date', 'solution_type_level_3']]=raw_data[['cust_id', 'lead_id','entity_type','workflow_node_id', 'sub_stage',\n",
    "       'q', 'created_at', 'updated_at','products_context','name_match_status','final_timestamp','panelqc_max_created','qc_pending_max_created','sbstage_count','fse_cust_id','agent_team','mid','mid_creation_date','solution_type_level_3']]\n",
    "       \n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Updated Timestamp']=pd.to_datetime(data['Updated Timestamp'])\n",
    "data['Created Timestamp']=pd.to_datetime(data['Created Timestamp'])\n",
    "data['QC Panel Successful TimeStamp']=pd.to_datetime(data['QC Panel Successful TimeStamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_date = datetime.now() - timedelta(days=2)\n",
    "\n",
    "#current_timestamp = pd.Timestamp.now().normalize()-timedelta(days=1)\n",
    "\n",
    "\n",
    "#print(current_timestamp)\n",
    "\n",
    "#print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_date = '2024-10-15'  # Example: YYYY-MM-DD format\n",
    "\n",
    "# Convert the combined string into a datetime object\n",
    "custom_timestamp = datetime.strptime(user_date, '%Y-%m-%d')\n",
    "\n",
    "print(custom_timestamp)\n",
    "print(type(custom_timestamp))\n",
    "\n",
    "current_day = custom_timestamp.day\n",
    "current_month = custom_timestamp.month\n",
    "current_year = custom_timestamp.year\n",
    "\n",
    "print(current_day)\n",
    "print(current_month)\n",
    "print(current_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now() - timedelta(days=7)\n",
    "current_day = current_date.day\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "print(current_date)\n",
    "\n",
    "data.loc[(data['Updated Timestamp'].dt.day>=current_day) &\n",
    "         (data['Updated Timestamp'].dt.month==current_month) &\n",
    "         (data['Updated Timestamp'].dt.year==current_year), 'Ageing']='Last 7 days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now() - timedelta(days=1)\n",
    "current_day = current_date.day\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "current_date\n",
    "\n",
    "data.loc[(data['Updated Timestamp'].dt.day==current_day) &\n",
    "         (data['Updated Timestamp'].dt.month==current_month) &\n",
    "         (data['Updated Timestamp'].dt.year==current_year), 'Ageing']='Yesterday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Ageing']=data['Ageing'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Ageing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.loc[data['Name_Match_Status']==True, ['Name_Match_Status', '10K/1rs MID Status']]=['Name Matched','10k MID created']\n",
    "\n",
    "data.loc[data['Name_Match_Status']==False, ['Name_Match_Status', '10K/1rs MID Status']]=['Name Not Matched','1Rs MID created']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Name_Match_Status']=data['Name_Match_Status'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Name_Match_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Product_Context'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Product_Context'].isin(['[]','[\"EDC\"]','[\"TAP_N_PAY\"]']),'Product_Context']='EDC'\n",
    "data['Product_Context'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[~data['Product_Context'].isin(['EDC']),'Product_Context']='NON_EDC'\n",
    "data['Product_Context'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mid_created_date']=pd.to_datetime(data['mid_created_date'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mid_created_date'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now() - timedelta(days=7)\n",
    "current_day = current_date.day\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "print(current_date)\n",
    "\n",
    "data.loc[ (data['Lead Status']== 'Documents Rejected (Pending at Sales Team)') & ((data['Updated Timestamp'].dt.day<current_day) &\n",
    "         (data['Updated Timestamp'].dt.month==current_month) &\n",
    "         (data['Updated Timestamp'].dt.year==current_year)), 'Rejection Ageing']='More Than 7 Days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now() - timedelta(days=7)\n",
    "current_day = current_date.day\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "current_date\n",
    "\n",
    "data.loc[ (data['Lead Status']== 'Documents Rejected (Pending at Sales Team)') & ((data['Updated Timestamp'].dt.day>=current_day) &\n",
    "         (data['Updated Timestamp'].dt.month==current_month) &\n",
    "         (data['Updated Timestamp'].dt.year==current_year)), 'Rejection Ageing']='6-7 Days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now() - timedelta(days=5)\n",
    "current_day = current_date.day\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "current_date\n",
    "\n",
    "data.loc[ (data['Lead Status']== 'Documents Rejected (Pending at Sales Team)') & ((data['Updated Timestamp'].dt.day>=current_day) &\n",
    "         (data['Updated Timestamp'].dt.month==current_month) &\n",
    "         (data['Updated Timestamp'].dt.year==current_year)), 'Rejection Ageing']='4-5 Days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_date = datetime.now() - timedelta(days=3)\n",
    "current_day = current_date.day\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "current_date\n",
    "\n",
    "data.loc[ (data['Lead Status']== 'Documents Rejected (Pending at Sales Team)') & ((data['Updated Timestamp'].dt.day>=current_day) &\n",
    "         (data['Updated Timestamp'].dt.month==current_month) &\n",
    "         (data['Updated Timestamp'].dt.year==current_year)), 'Rejection Ageing']='2-3 Days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now() - timedelta(days=1)\n",
    "current_day = current_date.day\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "current_date\n",
    "\n",
    "data.loc[ (data['Lead Status']== 'Documents Rejected (Pending at Sales Team)') & ((data['Updated Timestamp'].dt.day==current_day) &\n",
    "         (data['Updated Timestamp'].dt.month==current_month) &\n",
    "         (data['Updated Timestamp'].dt.year==current_year)), 'Rejection Ageing']='Less Than 1 Day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rejection Ageing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rejection Ageing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[~data['Entity_Type'].isin(['INDIVIDUAL','PROPRIETORSHIP']),'Entity_Type']='NON_PROPRIETORSHIP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Entity_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Lead Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rejected_timeStamp=data[(data['Lead Status']=='Documents Rejected (Pending at Sales Team)')&(data['Last QC Pending Timestamp'].isnull())]\n",
    "\n",
    "\n",
    "null_rejected_timeStamp=null_rejected_timeStamp[['Lead_ID']]\n",
    "\n",
    "print(len(null_rejected_timeStamp))\n",
    "\n",
    "null_rejected_timeStamp['id']=\"'\" + null_rejected_timeStamp['Lead_ID'] + \"'\" + \",\"\n",
    "\n",
    "null_rejected_timeStamp.head(3)\n",
    "\n",
    "null_rejected_timeStamp.to_csv(\"rejected_null.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dghdsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception(\"Stop execution here\")\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_null_value=pd.read_csv('rejected_null_value.csv')\n",
    "\n",
    "rejected_null_value['q']=pd.to_datetime(rejected_null_value['q'],format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "print(rejected_null_value.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rejected_null_value.head(3))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate the right DataFrame by taking the first occurrence per lead_id\n",
    "#rejected_agg = rejected_null_value.groupby('lead_id').first().reset_index()\n",
    "\n",
    "# Merge the DataFrames on the single column\n",
    "#data = data.merge(rejected_agg[['lead_id', 'Status']], left_on='Lead_ID', right_on='lead_id', how='left')\n",
    "\n",
    "# Fill in values based on conditions\n",
    "#data.loc[(data['Lead Status'] == 'Documents Rejected (Pending at Sales Team)') & (data['Last QC Pending Timestamp'].isnull()), 'Last QC Pending Timestamp'] = data['q']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.merge(rejected_null_value,left_on='Lead_ID',right_on='lead_id',how='left')\n",
    "\n",
    "data.loc[(data['Lead Status']=='Documents Rejected (Pending at Sales Team)') & (data['Last QC Pending Timestamp'].isnull()) ,'Last QC Pending Timestamp']=data['q']\n",
    "\n",
    "data=data.drop(columns=['lead_id','q'])\n",
    "\n",
    "print(data.columns)\n",
    "print(len(data[(data['Lead Status']=='Documents Rejected (Pending at Sales Team)')&(data['Last QC Pending Timestamp'].isnull())]))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Final TimeStamp']=pd.to_datetime(data['Final TimeStamp'])\n",
    "data['Last QC Pending Timestamp']=pd.to_datetime(data['Last QC Pending Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data['Final TimeStamp'][0])\n",
    "\n",
    "print(type(data['Last QC Pending Timestamp'][0]))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Last QC Pending Timestamp'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data['Last QC Pending Timestamp']=pd.to_datetime(data['Last QC Pending Timestamp'], errors='coerce')\n",
    "\n",
    "# Define the start and end times\n",
    "start_time = time(8, 30, 0)\n",
    "end_time = time(21, 30, 0)\n",
    "\n",
    "\n",
    "\n",
    "# Apply the condition to classify as 'Intime' or 'Offtime' based on the time component of 'N'\n",
    "data['Working TimeSlab'] = data['Last QC Pending Timestamp'].apply(lambda x: 'Offtime' if pd.isna(x) else ('Intime' if start_time <= x.time() <= end_time else 'Offtime'))\n",
    "\n",
    "\n",
    "data['Working TimeSlab'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Working TimeSlab'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_time_start = pd.to_datetime(\"21:30\").time()\n",
    "out_time_end = pd.to_datetime(\"23:59:59\").time()\n",
    "morning_time_end = pd.to_datetime(\"08:30\").time()\n",
    "\n",
    "data['Last QC Pending Timestamp'] = pd.to_datetime(data['Last QC Pending Timestamp'], errors='coerce')\n",
    "\n",
    "\n",
    "# Apply conditions to create column R\n",
    "def process_timestamp(row):\n",
    "    timestamp = row['Last QC Pending Timestamp']\n",
    "    \n",
    "    # Check if timestamp is NaT\n",
    "    if pd.isna(timestamp):\n",
    "        return np.nan\n",
    "    \n",
    "    time = timestamp.time()\n",
    "    \n",
    "    if row['Working TimeSlab'] == 'Offtime':\n",
    "        if out_time_start <= time <= out_time_end:\n",
    "            # Condition 1: Increment date by 1\n",
    "            return timestamp + pd.DateOffset(days=1)\n",
    "        elif time < morning_time_end:\n",
    "            # Condition 2: Return the same timestamp\n",
    "            return timestamp\n",
    "    # Condition 3: Return blank for 'intime'\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "data['New Off Time'] = data.apply(process_timestamp, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create S column based on R\n",
    "def generate_s(row):\n",
    "    if pd.notna(row['New Off Time']):  # If R is not NaT or blank\n",
    "        # Set time to 08:30 on the same date as R\n",
    "        return row['New Off Time'].replace(hour=8, minute=30, second=0)\n",
    "    else:\n",
    "        # If R is NaT or blank, copy the value from Q\n",
    "        return row['Last QC Pending Timestamp']\n",
    "    \n",
    "\n",
    "data['New Last QC Pending Time'] = data.apply(generate_s, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between L and S and format it as HH:mm:ss\n",
    "def calculate_difference(row):\n",
    "    if isinstance(row['New Last QC Pending Time'], pd.Timestamp) and isinstance(row['Final TimeStamp'], pd.Timestamp):\n",
    "        diff = row['Final TimeStamp'] - row['New Last QC Pending Time']\n",
    "        return diff  # Extract HH:mm:ss from Timedelta\n",
    "    return np.nan  # Return NaN if either L or S is not a timestamp\n",
    "\n",
    "# Apply function to create Difference column\n",
    "data['TAT'] = data.apply(calculate_difference, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TAT'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update TAT where it is negative to be the difference between L and N\n",
    "def adjust_negative_tat(row):\n",
    "    if pd.notna(row['TAT']) and row['TAT'] < pd.Timedelta(0):  # Check if TAT is negative\n",
    "        if isinstance(row['Final TimeStamp'], pd.Timestamp) and isinstance(row['Last QC Pending Timestamp'], pd.Timestamp):\n",
    "            return row['Final TimeStamp'] - row['Last QC Pending Timestamp']  # Calculate L - N if TAT is negative\n",
    "    return row['TAT']  # Keep original TAT if not negative\n",
    "\n",
    "# Apply function to adjust negative TAT values\n",
    "data['TAT'] = data.apply(adjust_negative_tat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[['Final TimeStamp','Last QC Pending Timestamp','TAT']].head(10))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[((data['Lead Status']=='Merchant Live') | (data['Lead Status']=='Documents Rejected (Pending at Sales Team)'))&(data['TAT'].isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_time(td):\n",
    "    total_minutes = td.total_seconds() / 60  # Convert timedelta to total minutes\n",
    "    if total_minutes < 2:\n",
    "        return 'Leads QCed in less than 02 min'\n",
    "    elif 2 <= total_minutes < 5:\n",
    "        return 'Leads QCed in between 02 - 05 min'\n",
    "    elif 5 <= total_minutes < 10:\n",
    "        return 'Leads QCed in between 05 - 10 min'\n",
    "    elif 10 <= total_minutes < 15:\n",
    "        return 'Leads QCed in between 10 - 15 min'\n",
    "    elif 15 <= total_minutes < 30:\n",
    "        return 'Leads QCed in between 15 - 30 min'\n",
    "    elif 30 <= total_minutes < 60:\n",
    "        return 'Leads QCed in between 30 min - 01 hr'\n",
    "    else:\n",
    "        return 'leads QCed in more than 01 hr'\n",
    "\n",
    "\n",
    "\n",
    "data.loc[(data['Lead Status']=='Merchant Live') | (data['Lead Status']=='Documents Rejected (Pending at Sales Team)'),'Merchant QC TAT slab']=data['TAT'].apply(categorize_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Merchant QC TAT slab'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[data['solution_type_level_3']=='3P FSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['solution_type_level_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~((data['Entity_Type'].isin(['PROPRIETORSHIP', 'NON_PROPRIETORSHIP'])) & (data['Product_Context'] == 'EDC'))]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['solution_type_level_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"all_flow_data_25th April'25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert to datetime\n",
    "data['Last QC Pending Timestamp'] = pd.to_datetime(data['Last QC Pending Timestamp'])\n",
    "data['Final TimeStamp'] = pd.to_datetime(data['Final TimeStamp'])\n",
    "\n",
    "# Define active hours (08:30 AM - 09:30 PM)\n",
    "active_start_time = pd.to_timedelta('08:30:00')\n",
    "active_end_time = pd.to_timedelta('21:30:00')\n",
    "\n",
    "# Function to calculate active duration for each row\n",
    "def calculate_active_duration(row):\n",
    "    start = row['Last QC Pending Timestamp']\n",
    "    end = row['Final TimeStamp']\n",
    "    \n",
    "    # Check if either start or end is NaT\n",
    "    if pd.isna(start) or pd.isna(end):\n",
    "        return \"00:00:00\"  # Return 0 hours if either is NaT\n",
    "    \n",
    "    # Initialize total active duration\n",
    "    total_active_duration = pd.Timedelta(0)\n",
    "    \n",
    "    # Iterate over each date from start to end\n",
    "    for single_date in pd.date_range(start=start.date(), end=end.date()):\n",
    "        active_start = pd.Timestamp(single_date) + active_start_time\n",
    "        active_end = pd.Timestamp(single_date) + active_end_time\n",
    "        \n",
    "        # Determine the effective active period for this day\n",
    "        effective_start = max(start, active_start)\n",
    "        effective_end = min(end, active_end)\n",
    "\n",
    "        # If there's a valid active period, add its duration\n",
    "        if effective_start < effective_end:\n",
    "            total_active_duration += effective_end - effective_start\n",
    "\n",
    "    # Convert total active duration to hours\n",
    "    total_hours = total_active_duration.total_seconds() / 3600\n",
    "    \n",
    "    # Format the hours to HH:MM:SS\n",
    "    hours = int(total_hours)\n",
    "    minutes = int((total_hours - hours) * 60)\n",
    "    seconds = int(((total_hours - hours) * 60 - minutes) * 60)\n",
    "    \n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "# Apply the function to each row\n",
    "data['TAT'] = data.apply(calculate_active_duration, axis=1)\n",
    "\n",
    "# Display the result\n",
    "print(data[['Last QC Pending Timestamp', 'Final TimeStamp', 'TAT']])\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['TAT']=data['Final TimeStamp']-data['Last QC Pending Timestamp']\n",
    "# data['TAT']=data['TAT'].apply(lambda x: str(x).split()[-1] if pd.notna(x) else 'NaT')\n",
    "print(data.columns)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[['Final TimeStamp','Last QC Pending Timestamp','TAT']].head(10))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[((data['Lead Status']=='Merchant Live') | (data['Lead Status']=='Documents Rejected (Pending at Sales Team)'))&(data['TAT'].isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"TAT\"]=pd.to_timedelta(data['TAT'])\n",
    "\n",
    "\n",
    "\n",
    "print(data[['Final TimeStamp','Last QC Pending Timestamp','TAT']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data['TAT'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_time(td):\n",
    "    total_minutes = td.total_seconds() / 60  # Convert timedelta to total minutes\n",
    "    if total_minutes < 16:\n",
    "        return 'Leads QCed in less than 15 min'\n",
    "    elif 16 <= total_minutes < 36:\n",
    "        return 'Leads QCed in between 15-30 min'\n",
    "    elif 36 <= total_minutes < 66:\n",
    "        return 'Leads QCed in between 30 min -1 hr'\n",
    "    elif 66 <= total_minutes < 126:\n",
    "        return 'Leads QCed in between 1 - 2 hr'\n",
    "    elif 126 <= total_minutes < 186:\n",
    "        return 'Leads QCed in between 2-3 hr'\n",
    "    elif 186 <= total_minutes < 246:\n",
    "        return 'Leads QCed in between 3-4 hr'\n",
    "    else:\n",
    "        return 'leads QCed in more than 4 hrs'\n",
    "\n",
    "\n",
    "\n",
    "data.loc[(data['Lead Status']=='Merchant Live') | (data['Lead Status']=='Documents Rejected (Pending at Sales Team)'),'Merchant QC TAT slab']=data['TAT'].apply(categorize_time)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Merchant QC TAT slab'].value_counts())\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TAT'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to convert timedelta to HH:MM:SS format with cumulative hours\n",
    "def format_timedelta(td):\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    hours, remainder = divmod(total_seconds, 3600)  # Convert total seconds to hours\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f'{hours:02}:{minutes:02}:{seconds:02}'  # Format as HH:MM:SS\n",
    "\n",
    "# Apply the function to convert timedelta to HH:MM:SS\n",
    "data['TAT'] = data['TAT'].apply(format_timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['Lead Status']!='Merchant Live') & (data['Lead Status']!='Documents Rejected (Pending at Sales Team)'),'TAT']=''\n",
    "\n",
    "data['TAT'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['Working TimeSlab','New Off Time','New Last QC Pending Time','Node id'])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=data.pop('TAT')\n",
    "\n",
    "t=data.columns.get_loc('Merchant QC TAT slab')\n",
    "\n",
    "data.insert(t+1,'TAT',col)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['solution_type_level_3'].unique()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acup_kyc=data[data['solution_type_level_3'].isin(['ACCOUNT_UPGRADE', 'KYC_UPDATE'])]\n",
    "data_mco=data[~data['solution_type_level_3'].isin(['ACCOUNT_UPGRADE', 'KYC_UPDATE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raise Exception(\"Stop execution here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"all_flow_data_21st Oct'24.xlsx\") as writer:\n",
    "    # Write the original dataframe to the first sheet\n",
    "    data.to_excel(writer, sheet_name='All Data', index=False)\n",
    "    \n",
    "    # Write data filtered by Category 'A' and 'C' to the second sheet\n",
    "    data_acup_kyc.to_excel(writer, sheet_name=' KYC & ACC UPGD', index=False)\n",
    "    \n",
    "    # Write data filtered by Category 'B' and 'D' to the third sheet\n",
    "    data_mco.to_excel(writer, sheet_name='MCO', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"all_flow_data_19th Oct'24.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
